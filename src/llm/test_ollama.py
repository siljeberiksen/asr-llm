from typing import Optional

from ollama import ChatResponse, chat
from pydantic import BaseModel
from pydantic.types import JsonSchemaValue, Literal

model = "hf.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF:Q6_K"
#model = "hf.co/unsloth/Llama-3.2-3B-Instruct-GGUF:Q6_K"


def generate(
    # system_prompt: str,  # prøv uten først.
    prompt: str,
    schema: Optional[JsonSchemaValue] = None,
    parse: bool = True,
    num_ctx: int = 48000,
    num_predict: int = 4000,
    temperature: float = 0.0,
) -> str:
    response: ChatResponse = chat(
        model=model,
        messages=[
            # {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt},
        ],
        options={
            "num_ctx": num_ctx,
            "num_predict": num_predict,
            "top_k": 100,
            "top_p": 0.8,
            "temperature": temperature,
            "seed": 0,  # this is not needed when temp is 0
            "repeat_penalty": 1.3,  # remain default for json outputs, from experience.
        },
        format=schema,
        stream=False,
    )
    res = response.message.content
    if parse and schema:
        try:
            res = eval(res)
        except Exception:
            res = None
    return res


prompt_asr = """
You are an ASR transcript selector.
Perform language model rescoring based on the top-5 outputs generated by an Automatic Speech Recognition (ASR) system given a conversational history.
Select the most accurate ASR transcription.

___
History:
{history}
___

The ASR hypotheses are as follows:
{hypotheses}

Output the integer index N of the most suitable ASR transcription from the <option N> hypothesis.
"""

history = [
    "Hey, did you watch the game last night?",
    "Yeah, it was crazy! I can’t believe that last-minute goal.",
    "Right? The defense just fell apart.",
    "I know, and the referee’s call was super questionable.",
    "Yeah, but honestly, they should have played better in the first half.",
]
hypotheses = [
    "They had so many mixed chances early on. ",
    "They had so many missed chants early on. ",
    "They had some money missed chances early on. ",
    "They had so many missed chances early on. ",
    "They had so many missed chance early on. ",
]
history_str = "\n\n".join(history)
hypo = [f"<option{i+1}> {h.strip()} </option{i+1}>" for i, h in enumerate(hypotheses)]
hypo_str = "\n".join(hypo)
print(history_str)
print(hypo_str)

prompt = prompt_asr.format(
    history=history_str,
    hypotheses=hypo_str,
)
print(prompt)


class HypothesisSelector(BaseModel):
    selected: Literal[1, 2, 3, 4, 5]


print(
    generate(
        prompt=prompt,
        schema=HypothesisSelector.model_json_schema(),
    )
)